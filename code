import cv2  # OpenCV 라이브러리를 불러옵니다.
import easyocr  # OCR 엔진인 easyocr를 불러옵니다.
import numpy as np  # numpy 라이브러리를 불러옵니다.
from PIL import ImageFont, ImageDraw, Image  # PIL 라이브러리에서 필요한 모듈을 불러옵니다.
from googletrans import Translator  # googletrans에서 Translator 모듈을 불러옵니다.
from gtts import gTTS  # gTTS 모듈을 불러옵니다.
import pygame  # pygame 라이브러리를 불러옵니다.
import re  # 정규 표현식 라이브러리를 불러옵니다.
import time  # 시간 관련 라이브러리를 불러옵니다.
import os  # 운영체제 관련 작업을 위한 라이브러리를 불러옵니다.

def play_mp3_file(file_path):  # MP3 파일을 재생하는 함수를 정의합니다.
    pygame.mixer.init()  # pygame 믹서를 초기화합니다.
    pygame.mixer.music.load(file_path)  # MP3 파일을 불러옵니다.
    pygame.mixer.music.play()  # MP3 파일을 재생합니다.

    while pygame.mixer.music.get_busy():  # 음악이 재생되는 동안에는
        pygame.time.Clock().tick(10)  # 10ms마다 체크합니다.

    pygame.mixer.quit()  # 재생이 끝나면 믹서를 종료합니다.

def synthesize_and_play_text(text, lang='ko'):  # 텍스트를 음성으로 변환하고 재생하는 함수를 정의합니다.
    tts = gTTS(text=text, lang=lang)  # 텍스트를 음성으로 변환합니다.
    tts.save('output.mp3')  # 음성 데이터를 'output.mp3' 파일로 저장합니다.
    play_mp3_file('output.mp3')  # 'output.mp3' 파일을 재생합니다.

reader = easyocr.Reader(['de'])  # 독일어를 인식할 수 있는 OCR reader를 생성합니다.
translator = Translator()  # 번역기를 생성합니다.
cap = cv2.VideoCapture(0)  # 웹캠을 연결합니다.

ocr_result = ''  # OCR 결과를 저장할 변수를 초기화합니다.
trans_result = ''  # 번역 결과를 저장할 변수를 초기화합니다.
font = ImageFont.truetype('C:/Users/YunJanghyuk/Desktop/LINESeedKR-Rg.ttf', 30)  # 글꼴과 크기를 설정합니다.

while cap.isOpened():  # 웹캠이 연결되어 있는 동안에는
    ret, frame = cap.read()  # 웹캠에서 프레임을 읽어옵니다.
    if not ret:  # 프레임을 읽어오지 못하면
        break  # 반복문을 종료합니다.

    result_frame = frame.copy()  # 프레임을 복사하여 결과 프레임을 만듭니다.

    key = cv2.waitKey(1) & 0xFF  # 사용자의 키 입력을 받습니다.
    if key == ord('q'):  # 'q' 키가 눌리면
        break  # 반복문을 종료합니다.
    elif key == ord(' '):  # 스페이스바가 눌리면
        cv2.imwrite('captured_frame.png', frame)  # 현재 프레임을 'captured_frame.png' 파일로 저장합니다.
        print("Frame captured and saved!")  # 프레임 캡처 성공 메시지를 출력합니다.
        key = cv2.waitKey(0) & 0xFF  # 사용자의 키 입력을 받습니다.
        file_path = 'captured_frame.png'  # 캡처한 이미지의 파일 경로를 저장합니다.

        # Preprocessing steps
        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)  # 이미지를 그레이스케일로 불러옵니다.
        _, image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)  # 이미지에 이진화를 적용합니다.
        image = cv2.medianBlur(image, 5)  # 이미지에 미디언 블러를 적용합니다.

        result = reader.readtext(image)  # 이미지에서 텍스트를 읽어옵니다.
        ocr_result = ""  # OCR 결과를 저장할 변수를 초기화합니다.
        trans_result = ''  # 번역 결과를 저장할 변수를 초기화합니다.
        if result:  # OCR 결과가 있으면
            # 결과를 y 좌표와 x 좌표에 따라 정렬합니다.
            result.sort(key=lambda bbox: (bbox[0][0][1], bbox[0][0][0]))
            for (bbox, text, prob) in result:  # OCR 결과를 순회하며
                # 숫자를 제거합니다.
                text = re.sub(r'\d+', '', text)
                # 모음이나 자음만으로 이루어진 2글자 이상의 문자열을 제거합니다.
                text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]{2,}', '', text)
                if text.strip():  # 공백만 있는 문자열을 제거합니다.
                    ocr_result += text + " "  # OCR 결과를 저장합니다.
            print(ocr_result)  # OCR 결과를 출력합니다.
            # 번역 요청을 재시도합니다.
            for i in range(5):  # 최대 5번 재시도합니다.
                try:
                    trans_result = translator.translate(ocr_result, src='de', dest='ko').text  # OCR 결과를 한국어로 번역합니다.
                    break  # 번역에 성공하면 재시도를 중단합니다.
                except Exception as e:  # 번역 중 오류가 발생하면
                    print(f"An error occurred: {e}")  # 오류 메시지를 출력합니다.
                    print("Retrying...")  # 재시도 메시지를 출력합니다.
                    time.sleep(5)  # 재시도 전에 5초간 대기합니다.
            print(trans_result)  # 번역 결과를 출력합니다.
            synthesize_and_play_text(trans_result)  # 번역 결과를 음성으로 변환하고 재생합니다.
        try:
            os.remove(file_path)  # 캡처한 이미지 파일을 삭제합니다.
            print(f"File '{file_path}' deleted successfully.")  # 파일 삭제 성공 메시지를 출력합니다.
        except FileNotFoundError:  # 파일을 찾을 수 없는 경우
            print(f"File '{file_path}' not found.")  # 파일 없음 메시지를 출력합니다.
        except Exception as e:  # 그 외의 오류가 발생한 경우
            print(f"An error occurred: {e}")  # 오류 메시지를 출력합니다.

    if ocr_result:  # OCR 결과가 있으면
        cv2.putText(result_frame, 'German : ' + ocr_result, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)  # OCR 결과를 화면에 출력합니다.

        korean_text = 'Korean : ' + trans_result  # 번역 결과를 저장합니다.

        img_pil = Image.fromarray(result_frame)  # 결과 프레임을 이미지로 변환합니다.
        draw = ImageDraw.Draw(img_pil)  # 이미지에 그릴 준비를 합니다.
        draw.text((10, 70), korean_text, font=font, fill=(255, 0, 0))  # 이미지에 번역 결과를 그립니다.
        result_frame = np.array(img_pil)  # 이미지를 다시 프레임으로 변환합니다.
    
    cv2.imshow('WebCam', result_frame)  # 결과 프레임을 화면에 출력합니다.

cap.release()  # 웹캠 연결을 종료합니다.
cv2.destroyAllWindows()  # 모든 창을 닫습니다.
